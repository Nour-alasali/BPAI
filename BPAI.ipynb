{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c2d5d7-e306-401d-860f-5aecb365b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import urllib.parse\n",
    "import unicodedata\n",
    "\n",
    "data_folder = os.path.join(os.getcwd(), 'data')\n",
    "extracted_data = []\n",
    "\n",
    "# Loading the spacy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "# a list of culinary measurement words and cooking adjectives and descriptions to exclude from results\n",
    "measurement_words = {\n",
    "    'acidic', 'add', 'aged', 'airy', 'alternative', 'aromatic', 'astringent', 'bake', 'bag', 'bags', 'barrel', \n",
    "    'battered', 'beat', 'beaten', 'big', 'bit', 'bite', 'bitesize', 'bland', 'blanched', 'blend', 'blended', 'blackened', \n",
    "    'bitter', 'block', 'boil', 'boneless', 'box', 'boxes', 'braise', 'braised', 'bread', \n",
    "    'breaded', 'brewed', 'brined', 'broil', 'brush', 'burn', 'burnt', 'buttery', 'bunch', 'bunches', 'can', 'candied', \n",
    "    'cap', 'caps', 'caramelize', 'carve', 'carved', 'carton', 'casserole', 'center', 'center-cut', 'centercut', 'chalky', \n",
    "    'charred', 'chewy', 'choice', 'chill', 'chop', 'chopped', 'chunk', 'chunks', 'chunky', 'classico', 'clove', 'cloves', 'cloying', \n",
    "    'coat', 'coated', 'cold', 'combine', 'conimex', 'cool', 'cook', 'cooked', 'cover', \n",
    "    'creamy', 'cracked', 'crisp', 'crispy', 'crunchy', 'crumbly', 'crush', 'crushed', 'cube', 'cubed', 'cubes', 'cup',\n",
    "    'cured', 'cut', 'dash', 'dashes', 'deglaze', 'dehydrated', 'deep-fry', 'deep-fried', 'degrees', 'diameter', 'dice', \n",
    "    'diced', 'directions', 'dip', 'dipped', 'dissolve', 'dollop', 'dozen', 'drain', 'dram', 'drizzle', 'dried', \n",
    "    'drizzled', 'dunk', 'dunked', 'dust', 'effervescent', 'ferment', 'fermented', 'filter', 'filled', 'finely', 'unfiltered',\n",
    "    'flambé', 'flaky', 'flat', 'flattened', 'flavored', 'flip', 'fold', 'foamy', 'fry', 'frying', \n",
    "    'frothy', 'firm', 'fluid', 'foamy', 'frozen', 'fried', 'g', 'gallon', 'gallons', 'garnish', 'garnished', 'gelatinous',\n",
    "    'glaze', 'glog', 'glug', 'gob', 'golden', 'gooey', 'gram', 'grams', 'grate', \n",
    "    'grated', 'grating', 'grill', 'grind', 'gritty', 'ground', 'head', 'heads', 'heat', 'hellmann', 'hellmanns', \n",
    "    'herbal', 'hole', 'holes', 'home', 'hour', 'hours', 'hot', 'hunk', 'inch', 'inches', 'inch-diameter', \n",
    "    'inch-thick', 'infuse', 'infused', 'instant', 'jar', 'jars', 'jigger', 'jug', 'julienne', 'jumbo', 'juicy', \n",
    "    'kg', 'kilogram', 'kilograms', 'knead', 'kneaded', 'layer', 'layered', 'layers', 'lb', 'lbs', 'leaf', 'leaves', \n",
    "    'lengthways', 'light', 'little', 'liter', 'liters', 'lukewarm', 'luke', 'mash', 'marinate', 'marinated', \n",
    "    'medley', 'medium', 'metallic', 'microwave', 'milky', 'milligram', 'milligrams', 'milliliter', 'milliliters', \n",
    "    'mince', 'minced', 'minute', 'minutes', 'minim', 'mix', 'mixed', 'ml', 'molded', 'moist', 'mushy', 'nip', \n",
    "    'nutty', 'one', 'ones', 'optional', 'ounce', 'ounces', 'oz', 'oz.', 'package', 'packages', 'pan', 'pans', \n",
    "    'parboiled', 'part', 'parts', 'pat', 'peck', 'peeled', 'peel', 'peels', 'peppery', 'perishable', 'piece', \n",
    "    'pieces', 'pickled', 'pinch', 'pint', 'pints', 'pkg', 'pkgs', 'plate', 'plates', 'poach', 'poached', 'pony', 'pour', \n",
    "    'pounded', 'powdered', 'preference', 'preserved', 'puree', 'quarter', 'quarters', 'quart', 'quarts', 'pinches',\n",
    "    'raw', 'refrigerate', 'refrigerated', 'rich', 'ripe', 'ripened', 'roast', 'roasted', 'roll', 'room', 'paperthin', 'paper', 'thin',\n",
    "    'salted', 'salt spoon', 'saute', 'sachet', 'scald', 'scalded', 'scrubbed', 'scoop', 'scoops', 'season', 'seasons', 'serve', \n",
    "    'sheet', 'sheets', 'shredded', 'shot', 'silky', 'simmer', 'size', 'sliced', 'slice', 'slices', 'sliver', 'toaster', 'l', 'colours',\n",
    "    'small', 'smidgen', 'smoke', 'smoky', 'smooth', 'soggy', 'sous-vide', 'splash', 'spongy', 'spoonful', 'spray', 'pouch', 'uncle', 'bens',\n",
    "    'sprinkled', 'stalk', 'stalks', 'steamed', 'steep', 'steeped', 'stem', 'stems', 'stew', 'stick', 'sticks', 'strain', 'garnishes', 'gr', 'm', 'e', 'glace', 'glaces', 'demiglace',\n",
    "    'strained', 'stuff', 'stuffed', 'sugar-free', 'sweetener', 'sweat', 'sweet', 't', 'tad', 'tablespoon', 'tablespoons', 'breyers', 'ith', 'cd',\n",
    "    'tablespoonful', 'tbsp', 'tbs', 'teacup', 'teaspoon', 'teaspoons', 'teaspoonful', 'teaspooon', 'temperature', 'tender', 'tablespoonfuls',\n",
    "    'third', 'thirds', 'thick', 'thickness', 'tiny', 'toast', 'toasted', 'toss', 'total', 'tps', 'tube', 'tub', 'tsps', 'tbsps', 'rabe', 'approx', 'approximately', 'approximatelyi',\n",
    "    'uncooked', 'unctuous', 'unsalted', 'use', 'velvety', 'warm', 'washed', 'waxy', 'well', 'whip', 'whipped', 'testing', 'purposes', 'gmofree',\n",
    "    'whisked', 'whole', 'wilted', 'woven', 'work', 'wrapped', 'zesty', 'heart', 'hearts', 'type', 'types', 'cage', 'parchment', 'microplane', 'grater',\n",
    "    'strip', 'pound', 'pounds', 'taste', 'cups', 'food', 'seedless', 'bonein', 'skinless', 'crosswise', 'lengthwise', 'length', 'inchwide', 'superfine',\n",
    "    'super','fine', 'handful', 'ingredient', 'squeeze', 'tspa', 'couple', 'handfuls', 'palmfuls', 'palmful', 'style', 'sift', 'spectrum', 'homemade',\n",
    "    'sprig', 'sprigs', 'root', 'roots', 'powder', 'paste', 'cooking', 'skinon', 'extract', 'round', 'bar', 'peeler', 'boiling', 'sweet', 'semisweet', 'allpurpose',\n",
    "    'all-purpose', 'pod', 'litre', 'tspoon', 'tbspoon', 'slit', 'mccormick', 'perfect', 'option', 'options', 'el', 'tl', 'ingredients', 'store', 'stores', 'places', 'place',\n",
    "    'boil', 'boilinbag', 'half', 'halves', 'container', 'bottle', 'and', 'ready', 'direction', 'saltfree', 'hawaiianstyle', 'lesssodium', 'large', 'tbso',\n",
    "    'fatfree', 'gm', 'tsp', 'tbsp', 'pc', 'sp', 'c', 'grocery', 'list', 'tblsp', 'bertolli', 'f', 'evoo', 'dish', 'dishes', 'thread', 'threads', 'skillet', 'skillets',\n",
    "    'whisk', 'min', 'max', 'leftover', 'leftovers', 'content', 'contents', 'cm', 'wedge', 'wedges', 'plu', 'brand', 'storebought', 'coin', 'coins', 'tolerance', 'kitchen', 'tips',\n",
    "    'skin-on', 'goodquality', 'crusty', 'mediumhot', 'hot', 'containers', 'surface', 'hands', 'glass', 'glasses', 'substitute', 'substitutes', 'round', 'rounds', 'groceries', \n",
    "    'brushing', 'bowl', 'bowls', 'hand', 'cans', 'flavor', 'flavour', 'flavors', 'flavours', 'recipe', 'recipes', 'combination', 'cms', 'gms', 'pcs', 'minimum', 'maximum',\n",
    "    'storage', 'situations', 'purpose', 'all', 'strips', 'loaf', 'loaves', 'square', 'circle', 'triangle',  'squares', 'circles', 'triangles', 'see', 'lengths', 'ball', 'balls', 'summer',\n",
    "    'wear', 'gloves', 'eyes', 'kids', 'husband', 'remove', 'gekookte', 'gepelde', 'knorr', 'posje', 'pakje', 'pak', 'pos', 'good', 'thereabouts', 'matchsticks', 'i', 'dairy', 'nondairy', 'instructions',\n",
    "    'prepared', 'precut', 'kikkoman', 'toppings', 'topping', 'franks', 'martins', 'marthas', 'bestquality', 'firmripe', 'firm', 'ripe', 'fresh',\n",
    "    'freshground', 'smokepoint', 'lowsodium', 'islands', 'cholesterol', 'low', 'cholestrol_free', 'market', 'foods', 'widthwise', 'necks', 'bulb',\n",
    "    'confectioners', 'grade', 'a', 'b', 'dayold','daysold','dayolds', 'ends', 'savory', 'tidbits', 'coarseground', 'fineground', 'w', 'chef', 'paul', 'serving', 'servings'\n",
    "}\n",
    "\n",
    "\n",
    "# extract noun and proper-noun ingredient words using POS and exclude stop words\n",
    "def extract_ingredients(ingredient_description):\n",
    "    doc = nlp(ingredient_description)\n",
    "    ingredients = [token.text for token in doc if token.pos_ in {'NOUN', 'PROPN'} and not token.is_stop]\n",
    "    return ' '.join(ingredients)\n",
    "\n",
    "# normalise ingredient words\n",
    "def normalize_ingredient(ingredient):\n",
    "    ingredient = ingredient.lower().strip()  # lower cases and strip leading/trailing spaces\n",
    "    ingredient = re.sub(r'[^\\w\\s]', '', ingredient)  #removing punctuation\n",
    "    ingredient = re.sub(r'\\s+', ' ', ingredient)  # removing extra whitespaces\n",
    "    ingredient = re.sub(r'\\d+\\/\\d+|\\d+|¼|½|¾|⅓|⅔|⅛|⅜|⅝|⅞', '', ingredient)  # removing fractions and numbers\n",
    "    ingredient = re.sub(r'[^\\x00-\\x7F]+', '', ingredient)  # Remove non-ASCII characters\n",
    "    ingredient_words = ingredient.split()\n",
    "    ingredient = ' '.join(word for word in ingredient.split() if word not in measurement_words)\n",
    "    #ingredient = '_'.join(word for word in ingredient.split() if word not in measurement_words and not nlp.vocab[word].is_stop)\n",
    "    return ingredient\n",
    "\n",
    "def preprocess_ingredients(ingredients):\n",
    "    normalized_ingredients = [normalize_ingredient(ingredient) for ingredient in ingredients]\n",
    "    extracted_ingredients = [extract_ingredients(ingredient) for ingredient in normalized_ingredients]\n",
    "    return extracted_ingredients\n",
    "\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith('.json'):\n",
    "        with open(os.path.join(data_folder, filename), 'r') as file:\n",
    "            data = json.load(file)\n",
    "            for item in data:\n",
    "                recipe_name = item.get('name')\n",
    "                ingredients = item.get('ingredients')\n",
    "                cuisine = item.get('cuisine')\n",
    "                if ingredients:\n",
    "                    ingredients = preprocess_ingredients(ingredients)\n",
    "                extracted_data.append({'recipe_name': recipe_name, 'ingredients': ingredients, 'cuisine': cuisine})\n",
    "\n",
    "print(extracted_data[:10])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e4a695-e7db-4937-a621-3835e0b7923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a translation table for unwanted characters to be replaced/removed\n",
    "single_char_replacements = str.maketrans({\n",
    "    ' ': '_', '&': 'and', '/': '_', '\"': '', \"'\": '', '’': '', '|': '', '(': '', ')': '', ',': '', '<':'', '>':'', '»':'', '«':'', '=':'',\n",
    "    '{': '', '}': '', '‘': '', '[': '', ']': '', '#': '', '–': '', '+': '', '®': '', ':': '', '“': '', '♥':'', '☀':'', '`':'', '©':'', 'ø': 'o',\n",
    "    '”': '', '�': '', '!': '', '—': '_', '$':'', '@':'_AT_', '?':'', 'Đ':'D', 'ı':'i', ';':'', '%':'perc', '*':'', '\\\\':'', 'ß':'ss',\n",
    "    '\\u2028': '', '\\ufeff': '', '\\u0096': '', '\\u200e': '', '\\u200f': '', '\\u0097': '', '\\u200b':'', '\\u2155':'', '\\u00ef': '', '\\u00bf': '', '\\u00bd': ''\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2130c36e-1370-41b3-9d09-9375199b251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import urllib.parse\n",
    "import unicodedata\n",
    "\n",
    "def normalize_text(text):\n",
    "    # normalise unicode characters and remove diacritics\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "    #translation table to remove unwanted characters\n",
    "    text = text.translate(single_char_replacements)\n",
    "    # unwanted multi-characters \n",
    "    text = text.replace('œu', 'eu').replace('21⁄2', 'two_and_half').replace('__ˊॢo◡ुoˋॢ_⁎','').replace('1⁄5', 'one_fifth').replace('Ai1⁄2oli','Aioli').replace('nbsp','').replace('...','').replace('.','').replace('~','').replace('__','_').replace('-','_')\n",
    "    # Remove non latin letters languages including Japanese, Chinese, Korean, and Thai characters\n",
    "    text = re.sub(r'[\\u3000-\\u303F\\u3040-\\u309F\\u30A0-\\u30FF\\u4E00-\\u9FFF\\uF900-\\uFAFF\\uAC00-\\uD7AF\\u1100-\\u11FF\\u3130-\\u318F\\u0E00-\\u0E7F\\u0370-\\u03FF\\u0980-\\u09FF\\u1200-\\u137F]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65560ddd-5b7b-4083-bcef-c2fad715d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import urllib.parse\n",
    "import unicodedata\n",
    "from rdflib import Graph, URIRef, Literal, Namespace, RDF, RDFS\n",
    "\n",
    "def create_valid_iri(base, name):\n",
    "    # normalisation and URL encoding\n",
    "    name = normalize_text(name)\n",
    "    return f'{base}{urllib.parse.quote(name)}'\n",
    "\n",
    "with open('recipes.ttl', 'w', encoding='utf-8') as f:\n",
    "    f.write('@prefix ex: <http://example.org/ontology/> .\\n')\n",
    "    f.write('@prefix recipe: <http://example.org/recipe/> .\\n')\n",
    "    f.write('@prefix ingredient: <http://example.org/ingredient/> .\\n')\n",
    "    f.write('@prefix cuisine: <http://example.org/cuisine/> .\\n')\n",
    "    f.write('@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\\n')\n",
    "    f.write('@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\\n\\n')\n",
    "\n",
    "    # classes\n",
    "    f.write('ex:Recipe a rdfs:Class .\\n')\n",
    "    f.write('ex:Ingredient a rdfs:Class .\\n')\n",
    "    f.write('ex:Cuisine a rdfs:Class .\\n\\n')\n",
    "\n",
    "    # properties (and their domain and range)\n",
    "    f.write('ex:RecipeHasIngredient a rdf:Property ;\\n')\n",
    "    f.write('    rdfs:domain ex:Recipe ;\\n')\n",
    "    f.write('    rdfs:range ex:Ingredient .\\n\\n')\n",
    "\n",
    "    f.write('ex:RecipeBelongsToCuisine a rdf:Property ;\\n')\n",
    "    f.write('    rdfs:domain ex:Recipe ;\\n')\n",
    "    f.write('    rdfs:range ex:Cuisine .\\n\\n')\n",
    "\n",
    "    f.write('ex:IngredientBelongstoRecipe a rdf:Property ;\\n')\n",
    "    f.write('    rdfs:domain ex:Ingredient ;\\n')\n",
    "    f.write('    rdfs:range ex:Recipe .\\n\\n')\n",
    "\n",
    "    f.write('ex:CuisineHasRecipe a rdf:Property ;\\n')\n",
    "    f.write('    rdfs:domain ex:Cuisine ;\\n')\n",
    "    f.write('    rdfs:range ex:Recipe .\\n\\n')\n",
    "\n",
    "    f.write('ex:RecipeHasName a rdf:Property ;\\n')\n",
    "    f.write('    rdfs:domain ex:Recipe ;\\n')\n",
    "    f.write('    rdfs:range rdfs:Literal .\\n\\n')\n",
    "\n",
    "    for recipe in extracted_data:\n",
    "        recipe_name = normalize_text(recipe[\"recipe_name\"])\n",
    "        cuisine_name = normalize_text(recipe[\"cuisine\"])\n",
    "        recipe_uri = create_valid_iri('recipe:', recipe_name)\n",
    "        cuisine_uri = create_valid_iri('cuisine:', cuisine_name)\n",
    "\n",
    "        f.write(f'{recipe_uri} a ex:Recipe .\\n')\n",
    "        f.write(f'{cuisine_uri} a ex:Cuisine .\\n')\n",
    "        f.write(f'{recipe_uri} ex:RecipeBelongsToCuisine {cuisine_uri} .\\n')\n",
    "        \n",
    "        recipe_name_literal = normalize_text(recipe[\"recipe_name\"]).replace('\"', '(').replace('\"', ')').replace(\"'\", '').replace(\"’\", \"\")\n",
    "        f.write(f'{recipe_uri} ex:RecipeHasName \"{recipe_name_literal}\" .\\n')\n",
    "\n",
    "        for ingredient in recipe['ingredients']:\n",
    "            ingredient_name = normalize_ingredient(ingredient).replace(\"'\", '').replace(\"’\", \"\")\n",
    "            if ingredient_name:\n",
    "                ingredient_uri = create_valid_iri('ingredient:', ingredient_name)\n",
    "                f.write(f'{ingredient_uri} a ex:Ingredient .\\n')\n",
    "                f.write(f'{recipe_uri} ex:RecipeHasIngredient {ingredient_uri} .\\n')\n",
    "                f.write(f'{ingredient_uri} ex:IngredientBelongstoRecipe {recipe_uri} .\\n')\n",
    "        \n",
    "        f.write(f'{cuisine_uri} ex:CuisineHasRecipe {recipe_uri} .\\n')\n",
    "\n",
    "print(\"RDF data written to recipes.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aac065-d3df-4671-b342-780e206bc0ce",
   "metadata": {},
   "source": [
    "Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343e173-978b-47f1-a8b4-a6d5228500d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "g = Graph()\n",
    "g.parse(\"recipes.ttl\", format=\"turtle\")\n",
    "\n",
    "# SPARQL query to get all ingredients and usage counts per cuisine\n",
    "query = \"\"\"\n",
    "PREFIX ex: <http://example.org/ontology/>\n",
    "PREFIX recipe: <http://example.org/recipe/>\n",
    "PREFIX ingredient: <http://example.org/ingredient/>\n",
    "PREFIX cuisine: <http://example.org/cuisine/>\n",
    "\n",
    "SELECT ?cuisine ?ingredient (COUNT(?recipe) AS ?usageCount)\n",
    "WHERE {\n",
    "  ?recipe ex:RecipeHasIngredient ?ingredient .\n",
    "  ?recipe ex:RecipeBelongsToCuisine ?cuisine .\n",
    "}\n",
    "GROUP BY ?cuisine ?ingredient\n",
    "ORDER BY ?cuisine DESC(?usageCount)\n",
    "\"\"\"\n",
    "results = g.query(query)\n",
    "\n",
    "# results conversion\n",
    "data = []\n",
    "for row in results:\n",
    "    cuisine = str(row.cuisine).split('/')[-1]\n",
    "    ingredient = str(row.ingredient).split('/')[-1]\n",
    "    usageCount = int(row.usageCount)\n",
    "    data.append((cuisine, ingredient, usageCount))\n",
    "df = pd.DataFrame(data, columns=[\"cuisine\", \"ingredient\", \"usageCount\"])\n",
    "\n",
    "#top 10 ingredients per cuisine\n",
    "top_ingredients_per_cuisine = df.groupby(\"cuisine\").apply(lambda x: x.nlargest(10, \"usageCount\")).reset_index(drop=True)\n",
    "\n",
    "#Print in table format\n",
    "print(tabulate(top_ingredients_per_cuisine, headers='keys', tablefmt='psql'))\n",
    "\n",
    "#visualisation\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(data=top_ingredients_per_cuisine, x='usageCount', y='ingredient', hue='cuisine', dodge=False)\n",
    "plt.title('Top 10 Ingredients per Cuisine')\n",
    "plt.xlabel('Usage Count')\n",
    "plt.ylabel('Ingredient')\n",
    "plt.legend(title='Cuisine', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bfaddd-a3c3-4615-86ff-3ffde9bcbb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "g = Graph()\n",
    "g.parse(\"recipes.ttl\", format=\"turtle\")\n",
    "\n",
    "# SPARQL query to count recipes per cuisine\n",
    "query = \"\"\"\n",
    "PREFIX ex: <http://example.org/ontology/>\n",
    "PREFIX recipe: <http://example.org/recipe/>\n",
    "PREFIX cuisine: <http://example.org/cuisine/>\n",
    "\n",
    "SELECT ?cuisine (COUNT(?recipe) AS ?recipeCount)\n",
    "WHERE {\n",
    "  ?recipe ex:RecipeBelongsToCuisine ?cuisine .\n",
    "}\n",
    "GROUP BY ?cuisine\n",
    "ORDER BY DESC(?recipeCount)\n",
    "\"\"\"\n",
    "results = g.query(query)\n",
    "\n",
    "data = []\n",
    "for row in results:\n",
    "    cuisine = str(row.cuisine).split('/')[-1]\n",
    "    recipeCount = int(row.recipeCount)\n",
    "    data.append((cuisine, recipeCount))\n",
    "df = pd.DataFrame(data, columns=[\"cuisine\", \"recipeCount\"])\n",
    "print(df)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=df, x='cuisine', y='recipeCount', palette='viridis')\n",
    "plt.title('Number of Recipes per Cuisine')\n",
    "plt.xlabel('Cuisine')\n",
    "plt.ylabel('Number of Recipes')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826c6e0c-695a-4c0e-a46d-992f0e749444",
   "metadata": {},
   "source": [
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147cb553-8ae7-40a3-bfe6-5ac7442171df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dash import Dash, dcc, html\n",
    "import plotly.express as px\n",
    "from dash.dependencies import Input, Output\n",
    "import re\n",
    "import time\n",
    "\n",
    "g = Graph()\n",
    "g.parse(\"recipes.ttl\", format=\"turtle\")\n",
    "\n",
    "# internal SPARQL query to get all ingredients with usage counts per cuisine\n",
    "query = \"\"\"\n",
    "PREFIX ex: <http://example.org/ontology/>\n",
    "PREFIX recipe: <http://example.org/recipe/>\n",
    "PREFIX ingredient: <http://example.org/ingredient/>\n",
    "PREFIX cuisine: <http://example.org/cuisine/>\n",
    "\n",
    "SELECT ?cuisine ?ingredient (COUNT(?recipe) AS ?usageCount)\n",
    "WHERE {\n",
    "  ?recipe ex:RecipeHasIngredient ?ingredient .\n",
    "  ?recipe ex:RecipeBelongsToCuisine ?cuisine .\n",
    "}\n",
    "GROUP BY ?cuisine ?ingredient\n",
    "ORDER BY ?cuisine DESC(?usageCount)\n",
    "\"\"\"\n",
    "results = g.query(query)\n",
    "\n",
    "data = []\n",
    "for row in results:\n",
    "    cuisine = str(row.cuisine).split('/')[-1]\n",
    "    ingredient = str(row.ingredient).split('/')[-1]\n",
    "    usageCount = int(row.usageCount)\n",
    "    data.append((cuisine, ingredient, usageCount))\n",
    "df = pd.DataFrame(data, columns=[\"cuisine\", \"ingredient\", \"usageCount\"])\n",
    "\n",
    "# extract the base ingredient name using first word\n",
    "def get_base_ingredient(ingredient_name):\n",
    "    return re.split(r'_|\\s', ingredient_name)[0]\n",
    "df['base_ingredient'] = df['ingredient'].apply(get_base_ingredient)\n",
    "\n",
    "# aggregate the usage counts by cuisine and base ingredient\n",
    "aggregated_df = df.groupby(['cuisine', 'base_ingredient']).agg({'usageCount': 'sum'}).reset_index()\n",
    "\n",
    "# Function and external SPARQL query to get country name and coordinates from Wikidata\n",
    "def get_country_coordinates(cuisine_name):\n",
    "    if cuisine_name == 'American':\n",
    "        # manually add coordinates for American cuisine (United States cuisine) \n",
    "        return 'United States', 37.0902, -95.7129\n",
    "    else:\n",
    "        cuisine_name += ' cuisine'\n",
    "        sparql_country = f\"\"\"\n",
    "        SELECT ?countryLabel WHERE {{\n",
    "          ?cuisine rdfs:label \"{cuisine_name}\"@en .\n",
    "          ?cuisine wdt:P17 ?country .\n",
    "          SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
    "        }}\n",
    "        \"\"\"  \n",
    "    url = 'https://query.wikidata.org/sparql'\n",
    "    \n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            response_country = requests.get(url, params={'query': sparql_country, 'format': 'json'})\n",
    "            response_country.raise_for_status()\n",
    "            response_country = response_country.json()\n",
    "            \n",
    "            try:\n",
    "                country = response_country['results']['bindings'][0]['countryLabel']['value']\n",
    "            except IndexError:\n",
    "                return None, None, None\n",
    "            \n",
    "            sparql_coordinates = f\"\"\"\n",
    "            SELECT ?coordinates WHERE {{\n",
    "              ?country rdfs:label \"{country}\"@en ;\n",
    "                       wdt:P31  wd:Q6256;\n",
    "                       wdt:P625 ?coordinates .\n",
    "            }}\n",
    "            \"\"\"\n",
    "            response_coordinates = requests.get(url, params={'query': sparql_coordinates, 'format': 'json'})\n",
    "            response_coordinates.raise_for_status()\n",
    "            response_coordinates = response_coordinates.json()\n",
    "            \n",
    "            try:\n",
    "                coordinates = response_coordinates['results']['bindings'][0]['coordinates']['value']\n",
    "                lon, lat = coordinates.replace('Point(', '').replace(')', '').split(' ')\n",
    "                return country, float(lat), float(lon)\n",
    "            except IndexError:\n",
    "                return country, None, None\n",
    "        \n",
    "        except requests.exceptions.RequestException:\n",
    "            time.sleep(2)\n",
    "    \n",
    "    return None, None, None\n",
    "\n",
    "# coordinates for each cuisine\n",
    "cuisine_data = []\n",
    "for cuisine in aggregated_df['cuisine'].unique():\n",
    "    country, lat, lon = get_country_coordinates(cuisine)\n",
    "    if country and lat and lon:\n",
    "        cuisine_data.append({'cuisine': cuisine, 'country': country, 'lat': lat, 'lon': lon})\n",
    "\n",
    "cuisine_df = pd.DataFrame(cuisine_data)\n",
    "aggregated_df = aggregated_df.merge(cuisine_df, on='cuisine')\n",
    "\n",
    "# using Dash app to create map. circle size and colour depend on usage count of ingredient and cuisine respectively.\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Input(id='ingredient-input', value='', type='text', placeholder='Enter ingredient'),\n",
    "    dcc.Graph(id='map')\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('map', 'figure'),\n",
    "    [Input('ingredient-input', 'value')]\n",
    ")\n",
    "def update_map(input_value):\n",
    "    if input_value:\n",
    "        filtered_df = aggregated_df[aggregated_df['base_ingredient'].str.contains(input_value, case=False)]\n",
    "    else:\n",
    "        filtered_df = aggregated_df\n",
    "    \n",
    "    fig = px.scatter_mapbox(\n",
    "        filtered_df,\n",
    "        lat=\"lat\",\n",
    "        lon=\"lon\",\n",
    "        hover_name=\"cuisine\",\n",
    "        hover_data=[\"base_ingredient\", \"usageCount\"],\n",
    "        color=\"cuisine\",\n",
    "        size=\"usageCount\",\n",
    "        size_max=15,\n",
    "        zoom=1,\n",
    "        height=600\n",
    "    )\n",
    "    fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
